# Module Context ‚Äî M√©moire & Ancrage (RAG Hybride)

Ce module est le cerveau mn√©sique de RAISE. Il est responsable de fournir au LLM le **Grounding** (V√©rit√© Terrain) n√©cessaire pour r√©pondre aux questions de l'ing√©nieur, en combinant connaissances techniques (Symbolique), documentation (S√©mantique) et historique (√âpisodique).

---

## üèóÔ∏è Architecture Globale (The 5-Pillars)

Le contexte repose d√©sormais sur une architecture orchestr√©e pour couvrir tous les horizons de donn√©es :

| Composant            | Fichier                   | R√¥le                                                                                                     | Technologie                         |
| :------------------- | :------------------------ | :------------------------------------------------------------------------------------------------------- | :---------------------------------- |
| **Orchestrateur**    | `orchestrator.rs`         | **Chef d'Orchestre**. Fusionne toutes les sources de contexte, g√®re le flux LLM et s√©curise les prompts. | Rust (Native)                       |
| **S√©mantique (RAG)** | `rag.rs`                  | **M√©moire Long-Terme**. Recherche vectorielle dans la documentation et les notes.                        | **SurrealDB** (Graph+Vec) ou Qdrant |
| **Symbolique**       | `retriever.rs`            | **V√©rit√© Terrain**. Scanne le mod√®le structur√© (`ProjectModel`) en RAM.                                  | Algorithmes de recherche floue      |
| **Session**          | `conversation_manager.rs` | **M√©moire de Travail**. G√®re le fil de discussion et la fen√™tre glissante (Sliding Window).              | Rust Structs                        |
| **Persistance**      | `memory_store.rs`         | **Stockage**. Sauvegarde/Charge les historiques de chat sur disque.                                      | JSON Files                          |

---

## üîÑ Flux de Donn√©es (Data Flow)

Tout passe d√©sormais par l'`AiOrchestrator`.

```mermaid
graph TD
    User[Utilisateur] -->|Question| Orch[AiOrchestrator]

    subgraph "Construction du Contexte"
        Orch -->|1. Get History| Session[Session Manager]
        Orch -->|2. Search Model| Symb[Symbolic Retriever]
        Orch -->|3. Search Docs| RAG[RAG Retriever]

        RAG -->|Embedding| NLP[NLP Engine]
        NLP -->|Vector| Store{Store Backend}

        Store -- "Hybrid Search" --> Surreal[(SurrealDB)]
        Store -- "Legacy" --> Qdrant[(Qdrant)]
    end

    subgraph "Inf√©rence"
        Symb & RAG & Session -->|Aggregated Prompt| Context[Context Builder]
        Context -->|Truncate Token| NLP
        NLP -->|Safe Prompt| LLM[LLM Client]
    end

    LLM -->|R√©ponse| Orch
    Orch -->|Save| Memory[Memory Store]
    Orch --> User
```

---

## ‚öôÔ∏è Configuration & Stockage

Le syst√®me de contexte est **agnostique** au moteur de base de donn√©es vectorielle. Il se configure via le fichier `.env`.

### Variables d'Environnement

```bash
# Choix du moteur (Recommand√© : surreal)
VECTOR_STORE_PROVIDER="surreal" # ou "qdrant"

# Si Qdrant est choisi (n√©cessite Docker)
PORT_QDRANT_GRPC=6334

# Si SurrealDB est choisi (Embarqu√©, pas de Docker requis)
# Active l'auto-vectorisation dans le GraphStore global
ENABLE_GRAPH_VECTORS=true

```

### Stockage Physique

Les donn√©es sont stock√©es localement dans le dossier d√©fini par `PATH_RAISE_DOMAIN` (par d√©faut `.raise_storage/`).

- `/chats` : Historiques de conversation (JSON).
- `/raise_graph.db` : Base de donn√©es SurrealDB (Graphe + Vecteurs).

---

## üìÇ D√©tails des Modules

### 1. L'Orchestrateur (`orchestrator.rs`)

C'est le point d'entr√©e unique. Il :

1. D√©tecte l'intention (Fast Path vs LLM).
2. Interroge les 3 m√©moires (Symbolique, RAG, Session).
3. Construit un prompt optimis√©.
4. Tronque le prompt pour respecter la fen√™tre de contexte du mod√®le (via `nlp::tokenizers`).
5. G√®re la r√©ponse et la sauvegarde.

### 2. Le RAG (`rag.rs`)

Il impl√©mente l'ingestion et la recherche documentaire.

- **Ingestion** : D√©coupe le texte (Chunking), calcule les vecteurs (BERT/All-MiniLM), et stocke le tout.
- **Retrieval** : Utilise la similarit√© cosinus pour trouver les morceaux de texte pertinents.
- **Backend** : Utilise une abstraction pour switcher entre `GraphStore` (Surreal) et `QdrantMemory`.

### 3. Gestionnaire de Session (`conversation_manager.rs`)

- G√®re l'historique `User` <-> `Assistant`.
- Impl√©mente une **fen√™tre glissante** (par d√©faut ~10 √©changes) pour ne pas saturer le LLM avec de vieilles discussions.

---

## üöÄ Commandes de Test

### Tester l'ensemble du contexte (Unitaires + Int√©gration)

```bash
# Lance les tests avec SurrealDB (par d√©faut)
cargo test ai::context -- --nocapture

# Lance les tests avec Qdrant (n√©cessite Docker)
cargo test ai::context -- --ignored

```

### Tester l'Orchestrateur (Pipeline complet simul√©)

```bash
cargo test ai::orchestrator

```

---

## üõ†Ô∏è √âtat d'avancement

- [x] **Retriever Symbolique** : Fonctionnel.
- [x] **RAG S√©mantique** : Fonctionnel (Multi-Backend).
- [x] **Conversation Manager** : Fonctionnel (Sliding Window).
- [x] **Memory Store** : Fonctionnel (Persistance JSON).
- [x] **Orchestrateur** : Fonctionnel (Router + Context Guard).
- [x] **Int√©gration GraphStore** : Fonctionnel (Hybrid Search).

```

```
