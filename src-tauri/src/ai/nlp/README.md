# Module `ai/nlp` ‚Äî Traitement du Langage Naturel

Ce module regroupe les outils de **bas niveau** pour la manipulation technique du texte dans RAISE. Il combine des approches **Symboliques** (R√®gles, Regex) et **S√©mantiques** (Vecteurs IA) pour pr√©parer les donn√©es avant leur traitement par les Agents ou le RAG.

Il sert de biblioth√®que utilitaire transversale pour `llm` (gestion du contexte) et `context` (pr√©paration des donn√©es RAG).

---

## üéØ Objectifs

1.  **Normalisation** : Nettoyer le texte utilisateur (accents, majuscules, stop words) pour standardiser les recherches.
2.  **Extraction d'Entit√©s** : Identifier les concepts cl√©s (Noms propres, Types Arcadia) sans appeler le LLM.
3.  **Vectorisation (Embeddings)** : Transformer le texte en vecteurs math√©matiques (`Vec<f32>`) via GPU ou CPU pour la recherche s√©mantique.
4.  **D√©coupage (Chunking)** : Diviser intelligemment les documents longs pour le RAG.

---

## üìÇ Architecture & Flux

Le module est divis√© en deux pipelines compl√©mentaires :

```mermaid
graph TD
    Input[Texte Utilisateur / Doc] --> Pre[Preprocessing & Normalisation]

    subgraph Symbolic_Path ["Pipeline Symbolique (Rapide)"]
        Pre --> Tokenizer[Tokenization Mots-Cl√©s]
        Pre --> Parser[Intention Simple Regex]
        Input --> Entities[Extraction Entit√©s Nomm√©es]
    end

    subgraph Semantic_Path ["Pipeline S√©mantique (IA)"]
        Input --> Splitter[D√©coupage Chunks]
        Splitter --> Embedder[G√©n√©ration Vecteurs 384d]
    end

    Parser --> Router[Routage Rapide]
    Embedder --> VectorDB[(Qdrant)]
```

---

## üß© Sous-Modules Impl√©ment√©s

### 1. `embeddings` (Moteur Vectoriel)

G√®re la transformation Texte -> Vecteur.

- **Support Hybride** : Utilise **Candle** (Rust Natif + GPU CUDA/Metal) par d√©faut, avec fallback sur **FastEmbed** (ONNX).
- **Mod√®le** : `all-MiniLM-L6-v2` (384 dimensions).
- **Documentation d√©taill√©e** : Voir `src-tauri/src/ai/nlp/embeddings/README.md`.

### 2. `preprocessing` (Nettoyage)

Pr√©pare le texte pour l'analyse.

- **Normalisation** : Conversion minuscule, suppression des accents (ex: "H√©l√®ne" -> "helene").
- **Stop Words** : Filtrage des mots vides fran√ßais ("le", "la", "pour", "avec"...).
- **Ponctuation** : Remplacement des caract√®res sp√©ciaux par des espaces.

### 3. `entity_extractor` (NER - Named Entity Recognition)

Extraction heuristique sans LLM (Regex).

- **Types Arcadia** : D√©tecte `Fonction`, `Composant`, `Acteur`, `Interface`, etc.
- **Noms Propres** : D√©tecte les s√©quences avec Majuscules (ex: "Station Sol").
- **Citations** : Capture le contenu entre guillemets.

### 4. `parser` (Intentions Rapides)

Classification d'intention bas√©e sur des r√®gles (Zero-Latency).

- D√©tecte les actions simples : `Create`, `Delete`, `Search`, `Explain`.
- Permet de court-circuiter le LLM pour des commandes basiques.

### 5. `splitting` (Chunking)

D√©coupage de documents pour le RAG.

- Utilise la crate `text-splitter`.
- Respecte la s√©mantique (paragraphes) et une limite de tokens d√©finie.

### 6. `tokenizers` (Analyse Lexicale)

Outils l√©gers pour la recherche par mots-cl√©s.

- `tokenize` : Produit une liste de mots-cl√©s normalis√©s.
- `truncate_tokens` : Coupe une cha√Æne pour respecter une fen√™tre contextuelle (heuristique).

---

## üöÄ Exemples d'Utilisation

### Pipeline de Recherche (Search)

```rust
use crate::ai::nlp::{preprocessing, tokenizers};

let query = "Je veux chercher le composant 'Moteur'";
// 1. Extraction Entit√©s
let entities = entity_extractor::extract_entities(query);
// -> Entity { text: "Moteur", category: QuotedLiteral }

// 2. Tokenization pour Index Invers√©
let keywords = tokenizers::tokenize(query);
// -> ["veux", "chercher", "composant", "moteur"]

```

### Pipeline d'Indexation (RAG)

```rust
use crate::ai::nlp::{splitting, embeddings};

let doc_content = "Texte tr√®s long...";
// 1. D√©coupage
let chunks = splitting::split_text_into_chunks(doc_content, 512);

// 2. Vectorisation (GPU si dispo)
let mut engine = embeddings::EmbeddingEngine::new()?;
let vectors = engine.embed_batch(chunks)?;

```

---

## üìä √âtat d'Avancement

| Composant            | Statut        | Technologie                    |
| -------------------- | ------------- | ------------------------------ |
| **Preprocessing**    | ‚úÖ Impl√©ment√© | Regex / Chars mapping          |
| **Embeddings**       | ‚úÖ Impl√©ment√© | Candle (GPU) / FastEmbed (CPU) |
| **Entity Extractor** | ‚úÖ Impl√©ment√© | Regex Heuristique              |
| **Parser (Intent)**  | ‚úÖ Impl√©ment√© | Rule-Based                     |
| **Splitter**         | ‚úÖ Impl√©ment√© | `text-splitter`                |
| **Tokenizers**       | ‚úÖ Impl√©ment√© | Whitespace / Heuristique       |

---

## ‚ö†Ô∏è Notes Techniques

- **Performance** : Le module est con√ßu pour √™tre "Zero-Latency" sur le chemin critique (Parser/Extractor). Seuls les Embeddings peuvent prendre quelques millisecondes (acc√©l√©r√©s par GPU).
- **Langue** : Optimis√© pour le **Fran√ßais** (Stopwords, Accents), mais compatible Anglais par d√©faut.

```

```

```

```
