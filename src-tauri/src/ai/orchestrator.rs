// FICHIER : src-tauri/src/ai/orchestrator.rs

use crate::ai::context::{
    conversation_manager::ConversationSession, memory_store::MemoryStore, rag::RagRetriever,
    retriever::SimpleRetriever,
};
use crate::ai::llm::client::{LlmBackend, LlmClient};
use crate::ai::nlp::parser::CommandType;
use crate::ai::world_model::{NeuroSymbolicEngine, WorldAction, WorldTrainer};
use crate::model_engine::types::{ArcadiaElement, ProjectModel};
use candle_nn::VarMap;

use crate::json_db::storage::StorageEngine;
use crate::utils::{io::PathBuf, prelude::*, Arc};

// --- CONFIGURATION ---
use crate::utils::config::AppConfig;

// --- IMPORTS AGENTS ---
use crate::ai::agents::intent_classifier::IntentClassifier;
use crate::ai::agents::{
    business_agent::BusinessAgent, data_agent::DataAgent, epbs_agent::EpbsAgent,
    hardware_agent::HardwareAgent, software_agent::SoftwareAgent, system_agent::SystemAgent,
    transverse_agent::TransverseAgent, Agent, AgentContext, AgentResult, CreatedArtifact,
};

pub struct AiOrchestrator {
    pub rag: RagRetriever,
    pub symbolic: SimpleRetriever,
    pub llm: LlmClient,
    pub session: ConversationSession,
    pub memory_store: MemoryStore,
    pub world_engine: NeuroSymbolicEngine,
    #[allow(dead_code)]
    world_engine_path: PathBuf,

    // R√©f√©rence au StorageEngine pour les Agents (Optionnel pour le mode l√©ger, requis pour les agents)
    storage: Option<Arc<StorageEngine>>,
}

impl AiOrchestrator {
    /// Constructeur
    pub async fn new(
        model: ProjectModel,
        storage_engine: Option<Arc<StorageEngine>>,
    ) -> RaiseResult<Self> {
        let app_config = AppConfig::get();

        // S√©curit√© : On r√©cup√®re le chemin du domaine via la config globale
        let Some(domain_path) = app_config.get_path("PATH_RAISE_DOMAIN") else {
            raise_error!(
                "ERR_CONFIG_DOMAIN_PATH_MISSING",
                error = "PATH_RAISE_DOMAIN est manquant dans la configuration AppConfig",
                context = json!({
                    "required_key": "PATH_RAISE_DOMAIN",
                    "action": "initialize_domain_context"
                })
            );
        };
        let chats_path = domain_path.join("chats");
        let brain_path = domain_path.join("world_model.safetensors");

        // üéØ 1. INSTANCIATION CENTRALE DE LA BASE DE DONN√âES
        let actual_storage = storage_engine.unwrap_or_else(|| {
            let storage_cfg = crate::json_db::storage::JsonDbConfig::new(domain_path.clone());
            Arc::new(StorageEngine::new(storage_cfg))
        });

        let manager = crate::json_db::collections::manager::CollectionsManager::new(
            &actual_storage,
            &app_config.system_domain,
            &app_config.system_db,
        );

        // üéØ 2. INJECTION DU MANAGER AUX SOUS-MOTEURS
        let rag = RagRetriever::new(&manager).await?;
        let symbolic = SimpleRetriever::new(model);
        let llm = LlmClient::new(&manager).await?;

        // Configuration du World Model (Neuro-Symbolique)
        let wm_config = app_config.world_model.clone();

        let world_engine = if brain_path.exists() {
            tracing::info!("üß† [Orchestrator] Chargement du World Model existant...");
            NeuroSymbolicEngine::load_from_file(&brain_path, wm_config.clone())
                .await
                .unwrap_or_else(|e| {
                    tracing::error!("‚ö†Ô∏è Erreur chargement cerveau, r√©initialisation: {}", e);
                    let vm = VarMap::new();
                    NeuroSymbolicEngine::new(wm_config.clone(), vm)
                        .expect("Echec fatal cr√©ation WorldModel")
                })
        } else {
            tracing::info!("‚ú® [Orchestrator] Cr√©ation d'un nouveau World Model vierge.");
            let vm = VarMap::new();
            NeuroSymbolicEngine::new(wm_config, vm)?
        };

        // Gestion de la m√©moire de conversation
        let memory_store = match MemoryStore::new(&chats_path).await {
            Ok(ms) => ms,
            Err(e) => raise_error!(
                "ERR_CHAT_MEMORY_STORE_INIT",
                error = e,
                context = json!({
                    "chats_path": chats_path.to_string_lossy(),
                    "component": "CHAT_SYSTEM"
                })
            ),
        };

        let session_id = "main_session";
        let session = memory_store.load_or_create(session_id).await?;

        Ok(Self {
            rag,
            symbolic,
            llm,
            session,
            memory_store,
            world_engine,
            world_engine_path: brain_path,
            storage: Some(actual_storage),
        })
    }

    /// Factory simple pour instancier les agents sp√©cialis√©s
    fn create_agent(&self, agent_id: &str) -> Option<Box<dyn Agent>> {
        match agent_id {
            "business_agent" | "business_analyst" => Some(Box::new(BusinessAgent::new())),
            "system_agent" | "system_architect" => Some(Box::new(SystemAgent::new())),
            "software_agent" | "software_engineer" => Some(Box::new(SoftwareAgent::new())),
            "hardware_agent" | "hardware_architect" => Some(Box::new(HardwareAgent::new())),
            "epbs_agent" | "configuration_manager" => Some(Box::new(EpbsAgent::new())),
            "data_agent" | "data_architect" => Some(Box::new(DataAgent::new())),
            "transverse_agent" | "quality_manager" => Some(Box::new(TransverseAgent::new())),
            _ => None,
        }
    }

    /// Point d'entr√©e principal : Ex√©cute une requ√™te utilisateur via le syst√®me multi-agents
    pub async fn execute_workflow(&mut self, user_query: &str) -> RaiseResult<AgentResult> {
        let _rag_context = self.rag.retrieve(user_query, 3).await.unwrap_or_default();
        let _arcadia_context = self.symbolic.retrieve_context(user_query);

        let classifier = IntentClassifier::new(self.llm.clone());
        let mut current_intent = classifier.classify(user_query).await;
        let mut current_agent_id = current_intent.recommended_agent_id().to_string();

        if current_agent_id == "orchestrator_agent" {
            let response = self.ask(user_query).await?;
            return Ok(AgentResult::text(response));
        }

        let session_scope = current_intent.default_session_scope();
        let global_session_id =
            AgentContext::generate_default_session_id("orchestrator", session_scope);

        let app_config = AppConfig::get();
        let Some(domain_path) = app_config.get_path("PATH_RAISE_DOMAIN") else {
            raise_error!(
                "ERR_CONFIG_DOMAIN_PATH_MISSING",
                error = "PATH_RAISE_DOMAIN est manquant dans la configuration AppConfig",
                context = json!({
                    "required_key": "PATH_RAISE_DOMAIN",
                    "action": "initialize_app_domain"
                })
            );
        };
        let dataset_path = app_config
            .get_path("PATH_RAISE_DATASET")
            .unwrap_or_else(|| domain_path.join("dataset"));

        let Some(storage_arc) = self.storage.clone() else {
            raise_error!(
                "ERR_AGENT_STORAGE_MISSING",
                error = "StorageEngine requis pour l'ex√©cution des agents",
                context = json!({
                    "component": "AGENT_RUNNER",
                    "action": "execute_agent"
                })
            );
        };

        let mut hop_count = 0;
        const MAX_HOPS: i32 = 5;
        let mut accumulated_artifacts: Vec<CreatedArtifact> = Vec::new();
        let mut accumulated_messages: Vec<String> = Vec::new();

        loop {
            if hop_count >= MAX_HOPS {
                accumulated_messages
                    .push("‚ö†Ô∏è Limite de redirections entre agents atteinte.".to_string());
                break;
            }

            // üéØ 3. LE .await MANQUANT AJOUT√â ICI !
            let ctx = AgentContext::new(
                &current_agent_id,
                &global_session_id,
                storage_arc.clone(),
                self.llm.clone(), // Le contexte re√ßoit directement le LLM instanci√© !
                domain_path.clone(),
                dataset_path.clone(),
            )
            .await;

            if let Some(agent) = self.create_agent(&current_agent_id) {
                tracing::info!("ü§ñ Activation Agent: {}", current_agent_id);

                let result_opt = agent.process(&ctx, &current_intent).await?;

                if let Some(res) = result_opt {
                    accumulated_artifacts.extend(res.artifacts);
                    accumulated_messages.push(res.message);

                    if let Some(acl_msg) = res.outgoing_message {
                        tracing::info!("üì° D√©l√©gation vers : {}", acl_msg.receiver);
                        current_agent_id = acl_msg.receiver.clone();
                        current_intent = classifier.classify(&acl_msg.content).await;
                        hop_count += 1;
                        continue;
                    } else {
                        break;
                    }
                } else {
                    break;
                }
            } else {
                accumulated_messages.push(format!(
                    "‚ùå Agent inconnu ou non impl√©ment√© : {}",
                    current_agent_id
                ));
                break;
            }
        }

        Ok(AgentResult {
            message: accumulated_messages.join("\n\n---\n\n"),
            artifacts: accumulated_artifacts,
            outgoing_message: None,
        })
    }

    pub async fn ask(&mut self, query: &str) -> RaiseResult<String> {
        self.session.add_user_message(query);

        let rag_ctx = self.rag.retrieve(query, 3).await.unwrap_or_default();
        let arcadia_ctx = self.symbolic.retrieve_context(query);

        let mut prompt = format!("Demande Utilisateur : {}\n\n", query);

        if !rag_ctx.is_empty() {
            prompt.push_str(&rag_ctx);
            prompt.push('\n');
        }
        if !arcadia_ctx.contains("Aucun √©l√©ment sp√©cifique") {
            prompt.push_str(&arcadia_ctx);
            prompt.push('\n');
        }

        let response = self
            .llm
            .ask(
                LlmBackend::LocalLlama,
                "Tu es un expert syst√®me Arcadia. Utilise le contexte documentaire (RAG) et structurel (Mod√®le) fourni pour r√©pondre avec pr√©cision.",
                &prompt,
            )
            .await?;

        self.session.add_ai_message(&response);
        let _ = self.memory_store.save_session(&self.session).await;

        Ok(response)
    }

    pub async fn reinforce_learning(
        &self,
        state_before: &ArcadiaElement,
        intent: CommandType,
        state_after: &ArcadiaElement,
    ) -> RaiseResult<f64> {
        let mut trainer = WorldTrainer::new(&self.world_engine, 0.01)?;

        let loss = trainer.train_step(state_before, WorldAction { intent }, state_after)?;

        let _ = self
            .world_engine
            .save_to_file(&self.world_engine_path)
            .await;

        Ok(loss)
    }

    pub async fn learn_document(&mut self, content: &str, source: &str) -> RaiseResult<usize> {
        self.rag.index_document(content, source).await
    }

    pub async fn clear_history(&mut self) -> RaiseResult<()> {
        self.session = ConversationSession::new(self.session.id.clone());
        let _ = self.memory_store.save_session(&self.session).await;
        Ok(())
    }
}

// =========================================================================
// TESTS UNITAIRES ET D'INT√âGRATION
// =========================================================================

#[cfg(test)]
mod tests {
    use super::*;
    use crate::ai::protocols::acl::{AclMessage, Performative};
    use crate::model_engine::types::NameType;
    use crate::utils::{data::HashMap, io::tempdir, AsyncMutex, OnceLock};

    fn get_hf_lock() -> &'static AsyncMutex<()> {
        static LOCK: OnceLock<AsyncMutex<()>> = OnceLock::new();
        LOCK.get_or_init(|| AsyncMutex::new(()))
    }

    fn make_element(id: &str) -> ArcadiaElement {
        ArcadiaElement {
            id: id.to_string(),
            name: NameType::default(),
            kind: "https://raise.io/ontology/arcadia/la#LogicalFunction".to_string(),
            description: None,
            properties: HashMap::new(),
        }
    }

    // üéØ HELPER POUR INJECTER LA BDD DE TEST AVANT L'ORCHESTRATEUR
    async fn setup_mock_orchestrator_env() -> Arc<StorageEngine> {
        crate::utils::config::test_mocks::inject_mock_config();
        let config = AppConfig::get();
        let storage_cfg = crate::json_db::storage::JsonDbConfig::new(
            config.get_path("PATH_RAISE_DOMAIN").unwrap(),
        );
        let storage = Arc::new(StorageEngine::new(storage_cfg));
        let manager = crate::json_db::collections::manager::CollectionsManager::new(
            &storage,
            &config.system_domain,
            &config.system_db,
        );
        manager.init_db().await.unwrap();

        crate::utils::config::test_mocks::inject_mock_component(&manager, "llm", crate::utils::json::json!({ "rust_tokenizer_file": "tokenizer.json", "rust_model_file": "qwen2.5-1.5b-instruct-q4_k_m.gguf" })).await;
        crate::utils::config::test_mocks::inject_mock_component(&manager, "nlp", crate::utils::json::json!({ "model_name": "minilm", "rust_config_file": "config.json", "rust_tokenizer_file": "tokenizer.json", "rust_safetensors_file": "model.safetensors" })).await;

        storage
    }

    #[tokio::test]
    #[serial_test::serial]
    #[cfg_attr(not(feature = "cuda"), ignore)]
    async fn test_orchestrator_init() {
        let _guard = get_hf_lock().lock().await;
        let _dir = tempdir().expect("temp dir");

        let storage = setup_mock_orchestrator_env().await;
        let orch = AiOrchestrator::new(ProjectModel::default(), Some(storage)).await;

        assert!(
            orch.is_ok(),
            "L'initialisation de l'orchestrateur a √©chou√© : {:?}",
            orch.err()
        );
        assert_eq!(orch.unwrap().session.id, "main_session");
    }

    #[tokio::test]
    async fn test_full_acl_path() {
        let msg = AclMessage::new(
            Performative::Request,
            "hardware",
            "quality_manager",
            "Verify",
        );
        assert_eq!(msg.receiver, "quality_manager");
    }

    #[tokio::test]
    #[serial_test::serial]
    #[cfg_attr(not(feature = "cuda"), ignore)]
    async fn test_learning_cycle() {
        let _guard = get_hf_lock().lock().await;
        let _dir = tempdir().expect("temp dir");

        let storage = setup_mock_orchestrator_env().await;
        let orch = AiOrchestrator::new(ProjectModel::default(), Some(storage))
            .await
            .unwrap();

        let loss = orch
            .reinforce_learning(&make_element("1"), CommandType::Create, &make_element("2"))
            .await;

        assert!(loss.is_ok(), "L'apprentissage a √©chou√© : {:?}", loss.err());
    }

    #[tokio::test]
    #[serial_test::serial]
    #[cfg_attr(not(feature = "cuda"), ignore)]
    async fn test_orchestrator_agent_factory() {
        let _guard = get_hf_lock().lock().await;
        let _dir = tempdir().expect("temp dir");

        let storage = setup_mock_orchestrator_env().await;
        let orch = AiOrchestrator::new(ProjectModel::default(), Some(storage))
            .await
            .unwrap();

        assert!(orch.create_agent("business_agent").is_some());
        assert!(orch.create_agent("system_architect").is_some());
        assert!(orch.create_agent("unknown_hacker_agent").is_none());
    }

    #[tokio::test]
    #[serial_test::serial]
    #[cfg_attr(not(feature = "cuda"), ignore)]
    async fn test_orchestrator_clear_history() {
        let _guard = get_hf_lock().lock().await;
        let _dir = tempdir().expect("temp dir");

        let storage = setup_mock_orchestrator_env().await;
        let mut orch = AiOrchestrator::new(ProjectModel::default(), Some(storage))
            .await
            .unwrap();

        // On purge l'historique r√©siduel potentiellement laiss√© par les tests pr√©c√©dents
        // qui ont utilis√© la m√™me base de donn√©es mock√©e.
        orch.clear_history().await.unwrap();

        // Maintenant on est s√ªr de partir de 0 !
        orch.session.add_user_message("Bonjour l'IA");
        orch.session.add_ai_message("Bonjour Humain");
        assert_eq!(orch.session.history.len(), 2);

        // Test du nettoyage
        let clear_res = orch.clear_history().await;
        assert!(clear_res.is_ok());
        assert_eq!(orch.session.history.len(), 0);
        assert_eq!(orch.session.id, "main_session");
    }

    #[tokio::test]
    #[serial_test::serial]
    #[cfg_attr(not(feature = "cuda"), ignore)]
    async fn test_orchestrator_learn_document() {
        let _guard = get_hf_lock().lock().await;
        let _dir = tempdir().expect("temp dir");

        let storage = setup_mock_orchestrator_env().await;
        let mut orch = AiOrchestrator::new(ProjectModel::default(), Some(storage))
            .await
            .unwrap();

        let content = "Raise est une plateforme incroyable combinant RAG et mod√®les formels.";
        let res = orch.learn_document(content, "documentation.txt").await;

        assert!(
            res.is_ok(),
            "L'apprentissage de document a √©chou√© : {:?}",
            res.err()
        );
        assert!(res.unwrap() > 0);
    }
}
