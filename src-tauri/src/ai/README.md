# Module AI ‚Äî Intelligence Artificielle Neuro-Symbolique

Ce module impl√©mente l'approche **MBAIE** (Model-Based AI Engineering) de RAISE. Il transforme le langage naturel en structures d'ing√©nierie formelles, valides et persist√©es.

## üéØ Vision & Philosophie

L'IA de RAISE n'est pas un simple chatbot. C'est un **op√©rateur qualifi√©** qui agit sur le mod√®le.

1.  **Workstation-First** : Par d√©faut, l'intelligence tourne localement (Mistral via Docker + Candle).
2.  **Dual Mode** : Capacit√© √† d√©border sur le Cloud (Gemini Pro) pour les t√¢ches complexes n√©cessitant un raisonnement sup√©rieur.
3.  **Grounding (Ancrage)** : L'IA ne r√©pond jamais "dans le vide". Elle est nourrie par le contexte r√©el du projet (`json_db`) via un syst√®me RAG Hybride.
4.  **Int√©grit√©** : Les actions de l'IA passent par les m√™mes validateurs (`x_compute`, Schema Validator) que les actions humaines.
5.  **Simulation** : Avant d'agir, l'IA "imagine" les cons√©quences de ses actions gr√¢ce √† un **World Model** pr√©dictif.

---

## üèóÔ∏è Architecture Modulaire

Le module est divis√© en quatre sous-syst√®mes interconnect√©s. Chaque sous-syst√®me poss√®de sa propre documentation d√©taill√©e.

### 1\\. [Le Cerveau Ex√©cutif (`agents/`)](./agents/README.md)

Responsable de la compr√©hension s√©mantique et de la construction des commandes.

- **Intent Classifier** : Analyse la demande (ex: "Cr√©e un acteur") et produit une structure Rust stricte.
- **Agents Sp√©cialis√©s** :
  - `SystemAgent` : Cr√©e/Modifie les √©l√©ments OA/SA (Acteurs, Fonctions).
  - _(Futur)_ `SoftwareAgent`, `HardwareAgent`.

### 2\\. [La M√©moire Contextuelle (`context/`)](./context/README.md)

Responsable de l'ancrage des r√©ponses dans la r√©alit√© du projet.

- **RAG Hybride** : Combine deux approches pour une pr√©cision maximale.
  - **Symbolique (`SimpleRetriever`)** : Recherche exacte par mots-cl√©s sur la structure du mod√®le en m√©moire.
  - **Vectoriel (`RagRetriever`)** : Recherche s√©mantique via **Qdrant** (base de donn√©es vectorielle) pour trouver des concepts similaires m√™me sans mots-cl√©s exacts.

### 3\\. [L'Infrastructure d'Inf√©rence (`llm/`)](./llm/README.md)

Responsable de la communication brute avec les mod√®les de langage.

- **Client Dual Mode** : Interface unifi√©e `ask()` qui route vers Local ou Cloud.
- **Moteur Natif** : Int√©gration de `candle` pour faire tourner des mod√®les l√©gers (Llama/Mistral) directement dans le binaire Rust (sans Docker).

### 4\\. [Le World Model (`world_model/`)](./world_model/README.md) ‚ú®

Responsable de la **Simulation** et de l'**Apprentissage**. C'est un "Jumeau Num√©rique Cognitif".

- **Architecture JEPA** : Pipeline Perception -> Repr√©sentation -> Dynamique.
- **Pr√©diction** : Estime l'impact d'une action (`Create`, `Delete`) sur l'√©tat latent du syst√®me.
- **Apprentissage** : S'am√©liore en continu via le feedback utilisateur (`reinforce_learning`).

---

## üîÑ Flux de Donn√©es (Orchestration)

L'orchestration est g√©r√©e par l'**`AiOrchestrator`** qui coordonne le LLM (Verbe), le RAG (M√©moire) et le World Model (Intuition).

```mermaid
graph TD
    User[Utilisateur] -->|Input| Orch[Orchestrateur]

    subgraph "M√©moire (RAG Hybride)"
        Orch -->|Keyword Search| SR[Simple Retriever]
        Orch -->|Semantic Search| Qdrant[(Qdrant Vector DB)]
        SR & Qdrant --> Context
    end

    subgraph "Fast Path : Intuition"
        Orch -->|Action?| WM[World Model]
        WM -->|Simulation| Pred[Pr√©diction Latente]
        Pred -->|Info| Orch
    end

    subgraph "Slow Path : Raisonnement"
        Orch -->|Context + Prompt| LLM[LLM Agent]
        LLM -->|JSON Action| DB[(JSON-DB)]
    end

    subgraph "Feedback Loop"
        DB -->|Real State| Trainer[World Trainer]
        Trainer -->|Update Weights| WM
    end

    Orch -->|R√©ponse| User

```

---

## üõ†Ô∏è Points d'Entr√©e

### 1\. Application GUI (Tauri)

L'utilisateur final interagit via le panneau de chat React.

- **Commande** : `ai_chat` (Conversation).
- **Commande** : `ai_confirm_learning` (Feedback pour le World Model).
- **Retour** : Flux textuel ou confirmation d'action.

### 2\. Outil D√©veloppeur (`ai_cli`)

Pour le test rapide, l'automatisation et le d√©bogage sans interface graphique.

- **Localisation** : `src-tauri/tools/ai_cli`.

---

## üìä √âtat d'Avancement (v0.2.0)

| Composant          | Statut    | Description                                             |
| ------------------ | --------- | ------------------------------------------------------- |
| **LLM Client**     | ‚úÖ Stable | Support Local/Cloud, Gestion d'erreurs.                 |
| **Classification** | ‚úÖ Stable | D√©tection pr√©cise (Create vs Chat).                     |
| **RAG Vectoriel**  | ‚úÖ Stable | Int√©gration **Qdrant** op√©rationnelle (`RagRetriever`). |
| **System Agent**   | ‚úÖ Actif  | Cr√©ation d'√©l√©ments OA/SA.                              |
| **World Model**    | üöÄ Alpha  | Simulation et Apprentissage (Backpropagation) actif.    |
| **Deep Learning**  | ‚úÖ Actif  | Support `candle-nn` et s√©rialisation `.safetensors`.    |

---

> **Note aux contributeurs :**
> Pour modifier la logique d'un agent, voir `src/ai/agents`.
> Pour ajuster la "physique" du cerveau IA, voir `src/ai/world_model`.
> Pour toucher √† la base de donn√©es, passer par `json_db::collections::manager`.

```

```
