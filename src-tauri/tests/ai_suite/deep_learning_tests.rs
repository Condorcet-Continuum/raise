// FICHIER : src-tauri/tests/ai_suite/deep_learning_tests.rs

use candle_core::{DType, Tensor};
use candle_nn::{VarBuilder, VarMap};
use raise::ai::deep_learning::models::sequence_net::SequenceNet;
use raise::ai::deep_learning::serialization;
use raise::ai::deep_learning::trainer::Trainer;
use raise::commands::ai_commands::DlState;
use raise::utils::config::{test_mocks, AppConfig}; // ğŸ¯ Import the config and mock injector
use std::fs;
use std::time::{SystemTime, UNIX_EPOCH};

#[test]
fn test_dl_e2e_integration() -> anyhow::Result<()> {
    // --- 1. CONFIGURATION ROBUSTE & ISOLÃ‰E ---
    // ğŸ¯ Inject the mock configuration to guarantee a stable testing environment
    test_mocks::inject_mock_config();
    let config = &AppConfig::get().deep_learning;
    let device = config.to_device(); // Automatically resolves to CPU per the mock config

    let state = DlState::new();

    let start = SystemTime::now();
    let since_the_epoch = start
        .duration_since(UNIX_EPOCH)
        .expect("Time went backwards");
    let unique_id = since_the_epoch.as_nanos();

    let filename = format!("test_integration_model_{}.safetensors", unique_id);
    let save_path = std::env::temp_dir().join(filename);

    println!("ğŸ“ Fichier de test temporaire : {:?}", save_path);

    // ğŸ¯ We no longer define input_dim, hidden_dim, output_dim here.
    // We use config.input_size, config.hidden_size, config.output_size.

    println!("--- Ã‰tape 1 : Initialisation du ModÃ¨le dans le State ---");
    {
        let varmap = VarMap::new();
        let vb = VarBuilder::from_varmap(&varmap, DType::F32, &device);
        // ğŸ¯ Use configuration values
        let model = SequenceNet::new(
            config.input_size,
            config.hidden_size,
            config.output_size,
            vb,
        )?;

        let mut model_guard = state.model.lock().unwrap();
        let mut varmap_guard = state.varmap.lock().unwrap();
        *model_guard = Some(model);
        *varmap_guard = Some(varmap);
    }

    println!("--- Ã‰tape 2 : EntraÃ®nement (1 pas) ---");
    {
        let model_guard = state.model.lock().unwrap();
        let varmap_guard = state.varmap.lock().unwrap();

        if let (Some(model), Some(varmap)) = (&*model_guard, &*varmap_guard) {
            // ğŸ¯ Use the intelligent from_config constructor
            let trainer = Trainer::from_config(varmap, config);
            let input = Tensor::randn(0f32, 1.0, (1, 1, config.input_size), &device)?;
            let target = Tensor::zeros((1, 1), DType::U32, &device)?;

            let loss = trainer.train_step(model, &input, &target)?;
            println!("Loss intÃ©gration : {}", loss);
            assert!(loss > 0.0);
        } else {
            panic!("Le modÃ¨le aurait dÃ» Ãªtre initialisÃ© !");
        }
    }

    println!("--- Ã‰tape 3 : Sauvegarde ---");
    {
        let varmap_guard = state.varmap.lock().unwrap();

        if let Some(varmap) = &*varmap_guard {
            serialization::save_model(varmap, &save_path)?;

            if !save_path.exists() {
                panic!("âŒ Le fichier n'a pas Ã©tÃ© crÃ©Ã© : {:?}", save_path);
            }
        } else {
            panic!("âŒ Erreur Ã‰tape 3 : VarMap est None.");
        }
    }

    println!("--- Ã‰tape 4 : Rechargement (Simulation redÃ©marrage) ---");
    let new_state = DlState::new();
    {
        // ğŸ¯ FIX: Pass only the path and the config object
        let model = serialization::load_model(&save_path, config)?;

        let mut model_guard = new_state.model.lock().unwrap();
        let mut varmap_guard = new_state.varmap.lock().unwrap();

        *model_guard = Some(model);
        *varmap_guard = None;
    }

    println!("--- Ã‰tape 5 : PrÃ©diction avec le modÃ¨le rechargÃ© ---");
    {
        let model_guard = new_state.model.lock().unwrap();
        if let Some(model) = &*model_guard {
            let input = Tensor::randn(0f32, 1.0, (1, 1, config.input_size), &device)?;
            let output = model.forward(&input)?;

            // ğŸ¯ Verify against the configured output size
            assert_eq!(output.dims(), &[1, 1, config.output_size]);
            println!("PrÃ©diction rÃ©ussie : {:?}", output.to_vec3::<f32>()?);
        } else {
            panic!("Le modÃ¨le rechargÃ© est introuvable !");
        }
    }

    if save_path.exists() {
        let _ = fs::remove_file(&save_path);
        println!("ğŸ—‘ï¸ Fichier temporaire nettoyÃ©.");
    }

    Ok(())
}
