# üéì Module d'Entra√Ænement IA (GenAptitude Trainer)

Ce module permet d'effectuer le **Fine-Tuning** (raffinage) de mod√®les de langage (LLM) √† partir des donn√©es export√©es par GenAptitude.

Il utilise la technique **QLoRA** (Quantized Low-Rank Adaptation) pour adapter efficacement un mod√®le g√©n√©rique (ex: Qwen 2.5) √† votre domaine sp√©cifique (Ing√©nierie Syst√®me, Arcadia, etc.).

## üìÇ Structure du Dossier

```text
tools/trainer/
‚îú‚îÄ‚îÄ dataset.jsonl       # Donn√©es d'entra√Ænement (g√©n√©r√© par le backend Rust)
‚îú‚îÄ‚îÄ train.py            # Script principal d'entra√Ænement (PyTorch/Peft/TRL)
‚îú‚îÄ‚îÄ requirements.txt    # Liste des d√©pendances Python
‚îî‚îÄ‚îÄ venv/               # Environnement virtuel (Local uniquement - Ignor√© par Git)

```

## üõ†Ô∏è Pr√©requis

Avant de lancer un entra√Ænement, vous devez g√©n√©rer le fichier de donn√©es `dataset.jsonl`.

- **Via la CLI Rust :** `cargo run --bin genaptitude ai_export_dataset`
- **Via l'Application :** En utilisant la commande d'export dans la Console D√©veloppeur.

---

## üöÄ Option A : Entra√Ænement Local (Linux / WSL)

Utilisez cette m√©thode si vous poss√©dez une machine √©quip√©e d'un **GPU NVIDIA performant** (RTX 3060/4060 ou sup√©rieur avec 8Go+ de VRAM).

### 1. Pr√©parer l'environnement

Ne lancez pas ces commandes en tant que root. Cr√©ez un environnement isol√© :

```bash
cd src-tauri/tools/trainer

# Cr√©ation de l'environnement virtuel
python3 -m venv venv

# Activation
source venv/bin/activate

# Installation des librairies
pip install -r requirements.txt

```

### 2. Lancer l'entra√Ænement

Assurez-vous que le fichier `dataset.jsonl` est pr√©sent dans le dossier.

```bash
python train.py

```

_Note : Si vous rencontrez des erreurs de m√©moire (OOM), r√©duisez le param√®tre `per_device_train_batch_size` dans `train.py`._

---

## ‚òÅÔ∏è Option B : Google Colab (Gratuit / GPU T4)

Utilisez cette m√©thode si vous n'avez pas de GPU d√©di√© ou si vous avez un GPU ancien (ex: GTX 9xx) incompatible avec les formats modernes.

**Le script `train.py` a √©t√© optimis√© pour les GPU Tesla T4 (offre gratuite Colab) en for√ßant le calcul en FP32 pour √©viter les erreurs BFloat16.**

### 1. Initialiser Google Colab

1. Rendez-vous sur [Google Colab](https://colab.research.google.com/).
2. Cr√©ez un **Nouveau Notebook**.
3. Allez dans le menu **Ex√©cution** > **Modifier le type d'ex√©cution**.
4. S√©lectionnez **T4 GPU** et validez.

### 2. Importer les fichiers

Dans le volet de gauche (ic√¥ne Dossier üìÅ), glissez-d√©posez les 3 fichiers suivants depuis votre dossier local `tools/trainer` :

- `train.py`
- `requirements.txt`
- `dataset.jsonl`

### 3. Installer les d√©pendances

Cr√©ez une cellule de code et ex√©cutez :

```python
!pip install -r requirements.txt

```

### 4. Lancer l'entra√Ænement

Cr√©ez une deuxi√®me cellule et ex√©cutez :

```python
!python train.py

```

### 5. R√©cup√©rer le mod√®le ("Cerveau")

Colab ne permet pas de t√©l√©charger un dossier directement. Compressez le r√©sultat :

```bash
!zip -r mon_modele.zip genaptitude-qwen-adapter

```

Ensuite, faites un clic droit sur `mon_modele.zip` dans le volet de fichiers et choisissez **T√©l√©charger**.

---

## ‚öôÔ∏è D√©tails Techniques

### Configuration du Script (`train.py`)

Le script est configur√© pour √™tre robuste face aux limitations mat√©rielles :

- **Mod√®le Cible :** `Qwen/Qwen2.5-1.5B-Instruct` (L√©ger et performant).
- **Quantization :** 4-bit (NF4) via `bitsandbytes`.
- **Mode Compatibilit√© T4 :**
- `bnb_4bit_compute_dtype = torch.float32` : Force les calculs en pr√©cision standard (√©vite les bugs sur architecture Turing/Pascal).
- `fp16 = False` & `bf16 = False` : D√©sactive la pr√©cision mixte pour garantir la stabilit√©.

- **WandB :** D√©sactiv√© par d√©faut (`os.environ["WANDB_DISABLED"] = "true"`) pour √©viter les interruptions.

### R√©sultat (Output)

L'entra√Ænement g√©n√®re un adaptateur LoRA compos√© de deux fichiers principaux :

- `adapter_config.json` : Les hyperparam√®tres du r√©seau.
- `adapter_model.safetensors` : Les poids entra√Æn√©s (environ 50-200 Mo).

## üì• Int√©gration dans GenAptitude

Pour utiliser votre mod√®le entra√Æn√© :

1. Cr√©ez le dossier de stockage :

```bash
mkdir -p ~/genaptitude-llm/ai-assets/lora

```

2. D√©compressez votre mod√®le √† l'int√©rieur.
3. Configurez votre fichier `.env` (si support√© par la version actuelle) :

```ini
RAISE_LORA_PATH=~/genaptitude-llm/ai-assets/lora/genaptitude-qwen-adapter

```

```


```
